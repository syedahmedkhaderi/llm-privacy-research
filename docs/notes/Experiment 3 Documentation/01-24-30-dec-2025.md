# Research Log - [24-30 December, 2025]

## Time Spent
- Total: 6 days

## What I Worked On Today
- Implemented script
- Script works but issue due to gpu limitation
- Thrashed everything and started from scatch due to precious experiment being a failure

## What I Learned
- 

## Problems I Encountered
- llama took 14~GB of GPU memory and was a pain to run other commands
- the paper used neo for baseline but i used llama-2-7b-chat which is apparently too safe and leaked 0 canaries
- got logged out of vertex and when i tried to login, it asked to contact admin. Got a reply but it didnt work.
- Not being able to get Claude help due to file being too large
- the colab notebook file is too big and i am getting lost all the time. Many mistakes are happening too. because of this

## Solutions/Progress
- decided to use non chat llama then will try neo for the baseline test according to the paper
- cleared cache often to free up space to run other commands in colab
- had to go with just .py file instead of ipynb since to fit claude size limit
- 

## Questions for Next Meeting
- Why did we chose to go with exposure over rouge?
- Why is llama-2-7b-chat so safe? Even AI is saying the same thing

## Following Week's Plan
- Execute everything correctly
- Try solving all the issues and problems
- Create report if successfull.
- Create report if not successful and getting same results.

## References
- Papers read:
- Code examples used: