\documentclass{article}
\usepackage{graphicx}
\usepackage{booktabs}
\usepackage{geometry}
\usepackage{float}
\usepackage{caption}
\usepackage{amsmath}
\usepackage{listings}
\usepackage{xcolor}

\geometry{a4paper, margin=1in}

\title{Analysis of RAG Impact on Canary Exposure in Large Language Models\\
\large{Experiment Report}}
\author{Syed Ahmed Khaderi}
\date{November 27, 2025}

\begin{document}

\maketitle

\section{Objective}
This experiment investigates how Retrieval-Augmented Generation (RAG) affects the privacy of sensitive information in Large Language Models (LLMs). We measure the exposure of synthetic "canaries" (fake but realistic personal data) inserted into a controlled dataset. A comparison is made between a baseline GPT-2 model and a GPT-2 model enhanced with RAG. The results show that RAG significantly increases exposure, in some cases by more than 200\%. We also study how the exposure metric changes with different sample sizes ($N=100$ and $N=1000$), finding that larger sample sizes provide more reliable and higher estimates of leakage.

\section{Experimental Setup and Configuration}

\subsection{Canary Generation}
We created four types of synthetic canaries using fixed templates and a constant random seed for reproducibility:

\begin{itemize}
    \item \textbf{Name:} "My name is \{First Last\}"
    \item \textbf{Email:} "My email is \{username\}@\{domain\}"
    \item \textbf{Phone:} "My phone number is \{area\}-\{prefix\}-\{line\}"
    \item \textbf{SSN:} "My social security number is \{area\}-\{group\}-\{serial\}"
\end{itemize}

\subsection{Corpus Construction}
We built a synthetic corpus of \textbf{1000 documents}:

\begin{itemize}
    \item \textbf{Templates:} 10 base templates mimicking business or administrative writings.
    \item \textbf{Insertion:} Canaries were embedded into these templates.
    \item \textbf{Distractors:} Neutral documents with generic text and no canaries.
    \item \textbf{Shuffling:} The full dataset was shuffled for random distribution.
\end{itemize}

\subsection{RAG System Architecture}
We implemented a standard RAG pipeline:

\begin{itemize}
    \item \textbf{Retriever:} Simple dense retriever based on \texttt{sentence-transformers}.
    \item \textbf{Embedding Model:} \texttt{all-MiniLM-L6-v2}
    \item \textbf{Index:} FAISS \texttt{IndexFlatIP} (inner-product search).
    \item \textbf{Retrieval:} Queries were derived from the beginning of each canary (e.g., "My name is").
    \item \textbf{Context Integration:} The top 3 retrieved documents were prepended to the canary prompt.
\end{itemize}

\subsection{Exposure Metric}
Model memorization was calculated using exposure, a score indicating how easily a canary could be recalled. Higher exposure means greater memorization risk. The formula used for computing:
\begin{equation}
\text{Exposure} = \log_2(N) - \log_2(\text{Rank})
\end{equation}

Where:
\begin{itemize}
    \item \(N\) is the total randomness space (1,000,000).
    \item \textbf{Rank} is the position of the canary when sorted by model perplexity.
\end{itemize}

We compute exposure for both $N=100$ and $N=1000$.

\section{Configurable Parameters}
The experiment allows several parameters to be adjusted to test different aspects of RAG impact on canary exposure:

\begin{enumerate}
    \item \textbf{num\_samples (Lineup Size):} Controls the number of candidate secrets in the exposure test.
    \item \textbf{top\_k (RAG Context Size):} Determines how many documents the RAG system retrieves. Current value: 3.
    
    \item \textbf{num\_corpus\_docs (Database Size):} Specifies the total number of documents in the retrieval corpus. Current value: 1000.
    \item \textbf{canary\_repetitions (Training Frequency):} Defines how often each canary appears in the training data. Current values: [1, 5, 10, 20, 50].
    \item \textbf{canaries\_per\_type (Sample Size per Type):} Sets the number of canaries tested per category. Current values: 5 (RAG) / 10 (Non-RAG).
\end{enumerate}
\section{Procedure}

\begin{enumerate}
    \item Measured perplexity for each canary using GPT-2 Small without any retrieval context (baseline).
    \item Indexed the corpus and retrieved the top-3 related documents for each canary.
    \item Provided retrieved documents as context and computed the model's perplexity on the canary.
    \item Computed exposure scores for each canary using the log-based formula.
    \item Plotted results to visualize exposure differences between RAG and non-RAG approaches.
\end{enumerate}

\section{Results and Observations}

Two key experiments were conducted with different sample sizes ($N=100$ and $N=1000$) to evaluate the impact of RAG on canary exposure.

\subsection{Non-RAG vs. RAG (N=100)}
The first experiment, shown in Figure 1, displays exposure values by canary type for $N=100$ candidates. The results demonstrate that RAG significantly increases exposure across all canary types, with names showing the highest increase at 208.3\%.

\begin{figure}[H]
    \centering
    \includegraphics[width=\textwidth]{./100-num-samples-plot.png}
    \caption{RAG impact on canary exposure with 100 samples}
\end{figure}

\begin{table}[H]
    \centering
    \caption{Mean Exposure Comparison for $N=100$}
    \label{tab:rag_vs_nonrag_100}
    \begin{tabular}{lcccc}
        \toprule
        \textbf{Canary Type} & \textbf{Non-RAG} & \textbf{RAG} & \textbf{Change} & \textbf{Std. Dev (RAG)} \\
        \midrule
        NAME  & 1.09 & 3.36 & +208.3\% & $\pm$1.32 \\
        EMAIL & 1.59 & 3.26 & +105.0\% & $\pm$2.31 \\
        PHONE & 1.98 & 3.45 & +74.2\% & $\pm$2.06 \\
        SSN   & 1.64 & 3.44 & +109.8\% & $\pm$2.23 \\
        \bottomrule
    \end{tabular}
\end{table}

\subsection{Non-RAG vs. RAG (N=1000)}
The second experiment, shown in Figure 2, examines exposure with $N=1000$ candidates. As expected, larger sample sizes reveal higher exposure values, with names showing a dramatic 333.7\% increase when RAG is applied.

\begin{figure}[H]
    \centering
    \includegraphics[width=\textwidth]{./1000-num-samples-plots.png}
    \caption{RAG impact on canary exposure with 1000 samples}
\end{figure}

\begin{table}[H]
    \centering
    \caption{Mean Exposure Comparison for $N=1000$}
    \label{tab:rag_vs_nonrag}
    \begin{tabular}{lcccc}
        \toprule
        \textbf{Canary Type} & \textbf{Non-RAG} & \textbf{RAG} & \textbf{Change} & \textbf{Std. Dev (RAG)} \\
        \midrule
        NAME  & 1.09 & 4.71 & +333.7\% & $\pm$1.76 \\
        EMAIL & 1.59 & 5.30 & +233.3\% & $\pm$3.88 \\
        PHONE & 1.98 & 5.45 & +175.9\% & $\pm$3.67 \\
        SSN   & 1.64 & 5.47 & +233.1\% & $\pm$3.81 \\
        \bottomrule
    \end{tabular}
\end{table}

\subsection{Effect of Sample Size}
Comparing the two experiments reveals that exposure consistently increases with larger sample sizes, as shown in Table 3.

\begin{table}[H]
    \centering
    \caption{Impact of Sample Size on RAG Exposure}
    \label{tab:sample_size}
    \begin{tabular}{lcc}
        \toprule
        \textbf{Canary Type} & \textbf{RAG (100)} & \textbf{RAG (1000)} \\
        \midrule
        NAME  & 3.36 & 4.71 \\
        EMAIL & 3.26 & 5.30 \\
        PHONE & 3.45 & 5.45 \\
        SSN   & 3.44 & 5.47 \\
        \bottomrule
    \end{tabular}
\end{table}

\subsection{Why RAG Increases Leakage}
RAG increases exposure primarily because the retriever often fetches documents that contain the full canary. When the model receives this document as context, the correct secret becomes much easier to predict, drastically lowering perplexity and raising exposure.

\subsection{Sensitivity to Sample Size}
Using $N=1000$ expands the possible exposure range (up to $\log_2(1000) \approx 9.97$). Exposure increases with larger $N$ because the true secret remains highly ranked even among many more distractors. Smaller $N$ values underestimate leakage severity.

\section{Conclusion}
This experiment demonstrated that RAG significantly increases the exposure of sensitive information in LLMs. When an LLM is linked to a retrieval system, sensitive data stored in the database can be surfaced through the generation process. All four data types showed substantial increases in exposure, confirming that RAG amplifies privacy risks. Names and phone numbers remain highly vulnerable due to their contextual integration, while SSNs and emails, though slightly less exposed in baseline conditions, show dramatic exposure increases under RAG. These findings highlight the need for careful privacy considerations when implementing RAG systems with sensitive data.

\end{document}
